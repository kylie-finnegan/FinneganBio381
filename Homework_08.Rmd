---
title: 'Homework #8'
author: "Kylie Finnegan"
date: "2023-03-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(MASS)
Data <- read.csv("CleanData.csv")
```

This data was imported from a csv, and it is data that I collected last year about protein ubiquitination state. The sample sizes are not equal due to availability of samples and the quality of the western blot. Ideally, a study would have an equal number of samples between the control and treatment groups, but sometimes that just doesn't happen. The new data is generated by first finding the mean, standard deviation, and sample size of each treatment group:

```{r}

ControlData <- filter(Data, Treatment=="Control") # n = 32
mean(ControlData$Intensity) # = 58736
sd(ControlData$Intensity) # = 19026
fitdistr(ControlData$Intensity,"normal")
# mean = 58736, sd = 18726

TreatmentData <- filter(Data, Treatment=="Heat shock") # n = 17
mean(TreatmentData$Intensity) # = 77600
sd(TreatmentData$Intensity) # = 17701
fitdistr(TreatmentData$Intensity,"normal")
# mean = 77600, sd = 17172

OGANOVA <- aov(Data$Intensity~Data$Treatment)
summary(OGANOVA)
# p=0.00146(**)

```

Then, you can use these values (mean, standard deviation, sample size) to generate new data for each treatment group that has the same parameters as the original data.

```{r}

NewControl <- rnorm(n=32, mean=58736, sd=19026)
NewControl <- matrix(NewControl)
Control <- rep("Control", 32)
NewControl <- cbind(NewControl, Control)


NewTreatment <- rnorm(n=17, mean=77600, sd=17701)
NewTreatment <- matrix(NewTreatment)
Treatment <- rep("Heat shock", 17)
NewTreatment <- cbind(NewTreatment, Treatment)


NewData <- rbind(NewControl, NewTreatment)
NewData <- data.frame(NewData)
NewData$V1 <- as.numeric(NewData$V1)
names(NewData) <- list("Intensity", "Treatment")

```

Then, run an ANOVA to determine if there is statistical significance between the treatment groups, and if it is of similar significance to an ANOVA run on the original data.

```{r}

ANOVA <- aov(NewData$Intensity~NewData$Treatment)
summary(ANOVA)

```

Re-run the analysis several times with random numbers generated from the same parameters, and see how much variation there is in the results.

ANOVA #1:
p-value = 2.06e-06(***)

ANOVA #2:
p-value = 0.000672(***)

ANOVA #3:
p-value = 0.00304(**)

When the analysis is re-run, the significance values change, but the degree of significance stays relatively similar due to having the same parameters. The degree of significance also is relatively similar to the ANOVA run on the original data (above).


Then, plot the data to visualize the distrbution (histogram) and the difference between the treatment groups (boxplot).

```{r}

Histogram <- ggplot(data=NewData, aes(x=Intensity, y=..density..)) +
  geom_histogram(color="black", fill="lightblue", 
                 linewidth=0.2)
print(Histogram)

Boxplot <- ggplot(data=NewData, aes(x=Treatment, y=Intensity)) +
  geom_boxplot(fill="lightblue")

print(Boxplot)

```


How small can the differences between the groups be (the “effect size”) for you to still detect a significant pattern (p < 0.05)?

Reduce treatment mean from 77600 to 67600:
(10,000 units was chosen as it is approximately half of the difference between the means of the original data).

```{r}

NewControl2 <- rnorm(n=32, mean=58736, sd=19026)
NewControl2 <- matrix(NewControl2)
Control2 <- rep("Control", 32)
NewControl2 <- cbind(NewControl2, Control2)


NewTreatment2 <- rnorm(n=17, mean=67600, sd=17701)
NewTreatment2 <- matrix(NewTreatment2)
Treatment2 <- rep("Heat shock", 17)
NewTreatment2 <- cbind(NewTreatment2, Treatment2)


NewData2 <- rbind(NewControl2, NewTreatment2)
NewData2 <- data.frame(NewData2)
NewData2$V1 <- as.numeric(NewData2$V1)
names(NewData2) <- list("Intensity", "Treatment")

ANOVA2 <- aov(NewData2$Intensity~NewData2$Treatment)
summary(ANOVA)
```

ANOVA #1: 
p-value = 0.0181(*)

ANOVA #2:
p-value = 0.261 (not significant)

ANOVA #3:
p-value = 0.125

Making the means more similar strongly reduces the significance of the difference between the groups, even though the other parameters are the same. The effect size is around 10,000 units, as this gives a significant ANOVA result only approximately 33% of the time. 


What is the minimum sample size you would need in order to detect a statistically significant effect?

Reduce both sample sizes by 5:
(The sample sizes were not huge to begin with, so I only reduced them a little. However, the "heat shock" treatment group has a smaller sample size, so 5 is the maximum I thought I could remove and still conduct a meaningful statistical analysis given the new, modified sample sizes).


```{r}

NewControl3 <- rnorm(n=27, mean=58736, sd=19026)
NewControl3 <- matrix(NewControl3)
Control3 <- rep("Control", 27)
NewControl3 <- cbind(NewControl3, Control3)


NewTreatment3 <- rnorm(n=12, mean=77600, sd=17701)
NewTreatment3 <- matrix(NewTreatment3)
Treatment3 <- rep("Heat shock", 12)
NewTreatment3 <- cbind(NewTreatment3, Treatment3)


NewData3 <- rbind(NewControl3, NewTreatment3)
NewData3 <- data.frame(NewData3)
NewData3$V1 <- as.numeric(NewData3$V1)
names(NewData3) <- list("Intensity", "Treatment")

ANOVA3 <- aov(NewData3$Intensity~NewData3$Treatment)
summary(ANOVA3)

```

ANOVA 1: 
p-value = 0.0747 (not significant)

ANOVA 2:
p-value = 0.0267(*)

ANOVA 3:
p-value = 0.0874 (not significant)

Having smaller sample sizes (n-5) strongly reduces the probability of significance, indicating that more data should be collected in order to run an analysis and have strong confidence in the accuracy of the results. The sample sizes from the original data (32 and 17) are probably the lowest I would accept to conduct a somewhat powerful analysis, and larger sample sizes are always better.

